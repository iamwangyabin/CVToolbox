{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import importlib\n",
    "import time\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "import DatasetsBuilder\n",
    "\n",
    "import getConfig\n",
    "config,unparsed=getConfig.get_lfconfig()\n",
    "\n",
    "import buildTrainNetwork\n",
    "import det_tools\n",
    "from inference import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../dataset/scan/train.tfrecord']\n",
      "aug_mode=random max_rad=3.141592653589793, max_scale_log=0.34642256747438094\n",
      "Add random logscale=-0.35~0.35, ori=-3.141592653589793~3.141592653589793\n"
     ]
    }
   ],
   "source": [
    "# tf.reset_default_graph() # for sure\n",
    "\n",
    "# log_dir = config.log_dir\n",
    "# batch_size = config.batch_size\n",
    "# optim_method = config.optim_method\n",
    "# learning_rate = config.lr\n",
    "# va_batch_size = 1\n",
    "\n",
    "tr_loader = DatasetsBuilder.SfMDataset(out_size=(362, 362), \n",
    "                   warp_aug_mode='random', flip_pair=True, max_degree=180, max_scale=1.414,\n",
    "                   num_threads=2)\n",
    "tr_dataset = tr_loader.get_dataset('../dataset', 'config.sfm_img_dir', \n",
    "                    'scan', phase='train',\n",
    "                    batch_size=6, shuffle=True)\n",
    "# config.depth_thresh = tr_loader.depth_thresh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = tr_dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "next_batch = list(next_element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_1:0\", shape=(?, ?), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "next_batch = DatasetsBuilder.euclidean_augmentation(next_batch, (config.data_size, config.data_size), config.rot_aug, config.scale_aug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_training_ph = tf.placeholder(tf.bool, shape=(), name='is_training')\n",
    "psf = tf.constant(det_tools.get_gauss_filter_weight(config.hm_ksize, config.hm_sigma)[:,:,None,None], dtype=tf.float32) \n",
    "global_step = tf.Variable(0, name='global_step', trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apply instance norm on input photos\n",
      "Act-Fn:  <function get_activation_fn.<locals>.<lambda> at 0x7f91f6bd9510>\n",
      "Apply 3D NMS instead.\n",
      "Scales (0.707107~1.41 #5): [1.41421356 1.18920712 1.         0.84089642 0.70710678]\n",
      "WARNING:tensorflow:From ../models/mso_resnet_detector.py:148: calling l2_normalize (from tensorflow.python.ops.nn_impl) with dim is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "dim is deprecated, use axis instead\n",
      "INFO:tensorflow:Summary name ConvOnlyResNet/ori_conv/weights:0 is illegal; using ConvOnlyResNet/ori_conv/weights_0 instead.\n",
      "INFO:tensorflow:Summary name ConvOnlyResNet/ori_conv/biases:0 is illegal; using ConvOnlyResNet/ori_conv/biases_0 instead.\n",
      "PAD=16, #conv=8, ksize=5 ori-ksize=5\n",
      "WARNING:tensorflow:From /home/wang/workspace/DeepLD/utils/det_tools.py:1729: calling reduce_max (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /home/wang/workspace/DeepLD/utils/det_tools.py:1730: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "Scales (0.707107~1.41 #5): [1.41421356 1.18920712 1.         0.84089642 0.70710678]\n",
      "PAD=16, #conv=8, ksize=5 ori-ksize=5\n",
      "Act-Fn:  <function relu at 0x7f920da089d8>\n",
      "===== SimpleDesc (reuse=False) =====\n",
      "#1 conv-bn-act (?, 16, 16, 64)\n",
      "#2 conv-bn-act (?, 8, 8, 128)\n",
      "#3 conv-bn-act (?, 4, 4, 256)\n",
      "FLAT (?, 4096)\n",
      "Feat-Norm: L2-NORM\n",
      "FEAT (?, 256)\n",
      "===== SimpleDesc (reuse=True) =====\n",
      "#1 conv-bn-act (?, 16, 16, 64)\n",
      "#2 conv-bn-act (?, 8, 8, 128)\n",
      "#3 conv-bn-act (?, 4, 4, 256)\n",
      "FLAT (?, 4096)\n",
      "Feat-Norm: L2-NORM\n",
      "FEAT (?, 256)\n",
      "===== SimpleDesc (reuse=True) =====\n",
      "#1 conv-bn-act (?, 16, 16, 64)\n",
      "#2 conv-bn-act (?, 8, 8, 128)\n",
      "#3 conv-bn-act (?, 4, 4, 256)\n",
      "FLAT (?, 4096)\n",
      "Feat-Norm: L2-NORM\n",
      "FEAT (?, 256)\n",
      "Random Hard Mining with scheduling #pickup=64-->5 (decay=0.9)\n"
     ]
    }
   ],
   "source": [
    "det_loss, desc_loss, det_endpoints, desc_endpoints, eval_endpoints, sift_endpoints = \\\n",
    "                    buildTrainNetwork.build_training_network(config, next_batch, is_training_ph, psf, global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_var_list = det_endpoints['var_list'] + det_endpoints['mso_var_list']\n",
    "desc_var_list = desc_endpoints['var_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'ConvOnlyResNet/init_conv/weights:0' shape=(5, 5, 1, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/init_conv/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/pre-bn/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/pre-bn/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/conv1/weights:0' shape=(5, 5, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/conv1/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/mid-bn/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/mid-bn/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/conv2/weights:0' shape=(5, 5, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-1/conv2/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/pre-bn/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/pre-bn/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/conv1/weights:0' shape=(5, 5, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/conv1/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/mid-bn/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/mid-bn/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/conv2/weights:0' shape=(5, 5, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-2/conv2/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/pre-bn/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/pre-bn/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/conv1/weights:0' shape=(5, 5, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/conv1/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/mid-bn/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/mid-bn/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/conv2/weights:0' shape=(5, 5, 16, 16) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/block-3/conv2/biases:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/fin-bn/gamma:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/fin-bn/beta:0' shape=(16,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_0/weights:0' shape=(5, 5, 16, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_0/biases:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_1/weights:0' shape=(5, 5, 16, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_1/biases:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_2/weights:0' shape=(5, 5, 16, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_2/biases:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_3/weights:0' shape=(5, 5, 16, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_3/biases:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_4/weights:0' shape=(5, 5, 16, 1) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/score_conv_4/biases:0' shape=(1,) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/ori_conv/weights:0' shape=(5, 5, 16, 2) dtype=float32_ref>,\n",
       " <tf.Variable 'ConvOnlyResNet/ori_conv/biases:0' shape=(2,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_var_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_optimizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-b4418e9548ba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdesc_minimize_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim_method\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc_var_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_var_and_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_histogram\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'get_optimizer' is not defined"
     ]
    }
   ],
   "source": [
    "    desc_minimize_op = get_optimizer(optim_method, global_step, learning_rate, desc_loss, desc_var_list, show_var_and_grad=config.show_histogram)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
